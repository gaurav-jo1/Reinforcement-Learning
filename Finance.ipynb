{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxJfYBVPTKpeW4m1iTBMOP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaurav-jo1/Reinforcement-Learning/blob/main/Finance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6JCtAQhvnXp"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from gym import spaces\n",
        "\n",
        "class TradingEnv(gym.Env):\n",
        "    def __init__(self, ticker=\"AAPL\", period=\"1y\"):\n",
        "        super(TradingEnv, self).__init__()\n",
        "        # Fetch data\n",
        "        self.data = yf.download(ticker, period=period)\n",
        "        self.data[\"Return\"] = self.data[\"Close\"].pct_change()\n",
        "        self.data[\"SMA_50\"] = self.data[\"Close\"].rolling(50).mean()\n",
        "        self.data[\"RSI\"] = self._compute_rsi(self.data[\"Close\"])\n",
        "        self.data = self.data.dropna()\n",
        "\n",
        "        # State: [price, return, SMA_50, RSI]\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(4,), dtype=np.float32)\n",
        "        self.action_space = spaces.Discrete(3)  # 0: hold, 1: buy, 2: sell\n",
        "\n",
        "        self.current_step = 0\n",
        "        self.cash = 10000  # Starting cash\n",
        "        self.shares = 0\n",
        "        self.max_steps = len(self.data) - 1\n",
        "\n",
        "    def _compute_rsi(self, prices, period=14):\n",
        "        delta = prices.diff()\n",
        "        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "        rs = gain / loss\n",
        "        return 100 - (100 / (1 + rs))\n",
        "\n",
        "    def reset(self, seed=None):\n",
        "        self.current_step = 0\n",
        "        self.cash = 10000\n",
        "        self.shares = 0\n",
        "        return self._get_observation(), {}\n",
        "\n",
        "    def _get_observation(self):\n",
        "        row = self.data.iloc[self.current_step]\n",
        "        return np.array([row[\"Close\"], row[\"Return\"], row[\"SMA_50\"], row[\"RSI\"]], dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        current_price = self.data.iloc[self.current_step][\"Close\"]\n",
        "        reward = 0\n",
        "\n",
        "        if action == 1 and self.cash >= current_price:  # Buy\n",
        "            self.shares += 1\n",
        "            self.cash -= current_price\n",
        "        elif action == 2 and self.shares > 0:  # Sell\n",
        "            self.shares -= 1\n",
        "            self.cash += current_price\n",
        "            reward = current_price - self.data.iloc[self.current_step - 1][\"Close\"]  # Profit\n",
        "\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "        next_state = self._get_observation() if not done else np.zeros(4)\n",
        "\n",
        "        # Portfolio value as info\n",
        "        info = {\"portfolio_value\": self.cash + self.shares * current_price}\n",
        "        return next_state, reward, done, False, info\n",
        "\n",
        "# Test it\n",
        "env = TradingEnv(\"AAPL\")\n",
        "state, _ = env.reset()\n",
        "for _ in range(5):\n",
        "    action = env.action_space.sample()  # Random action\n",
        "    next_state, reward, done, _, info = env.step(action)\n",
        "    print(f\"State: {next_state}, Reward: {reward}, Portfolio: {info['portfolio_value']}\")"
      ]
    }
  ]
}